{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "sentimentAnal = pickle.load(open('twitterSentimentMA.sav','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>date_tweeted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Snapchat so worthless now</td>\n",
       "      <td>2018-07-24T04:01:00.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>snapchatâs lame just text me</td>\n",
       "      <td>2018-07-24T04:12:37.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>if your bff doesnât share her/his location w...</td>\n",
       "      <td>2018-07-24T04:14:42.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Doing shit for Twitter, Instagram, Snapchat, o...</td>\n",
       "      <td>2018-07-24T04:19:46.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>your mcm typed out âViolence isnât the ans...</td>\n",
       "      <td>2018-07-24T04:23:22.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>âWomen......, please treat your man better. ...</td>\n",
       "      <td>2018-07-24T04:28:28.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Dear Snapchat, please apply a âall streaksâ...</td>\n",
       "      <td>2018-07-24T04:32:24.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Luis is big mad I lost our Snapchat streak LMA...</td>\n",
       "      <td>2018-07-24T04:47:48.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Remember back in the good old days when you cl...</td>\n",
       "      <td>2018-07-24T04:49:21.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>canât keep a snapchat streak because im not ...</td>\n",
       "      <td>2018-07-24T04:50:12.000Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body              date_tweeted\n",
       "0                          Snapchat so worthless now  2018-07-24T04:01:00.000Z\n",
       "1                     snapchatâs lame just text me  2018-07-24T04:12:37.000Z\n",
       "2  if your bff doesnât share her/his location w...  2018-07-24T04:14:42.000Z\n",
       "3  Doing shit for Twitter, Instagram, Snapchat, o...  2018-07-24T04:19:46.000Z\n",
       "4  your mcm typed out âViolence isnât the ans...  2018-07-24T04:23:22.000Z\n",
       "5  âWomen......, please treat your man better. ...  2018-07-24T04:28:28.000Z\n",
       "6  Dear Snapchat, please apply a âall streaksâ...  2018-07-24T04:32:24.000Z\n",
       "7  Luis is big mad I lost our Snapchat streak LMA...  2018-07-24T04:47:48.000Z\n",
       "8  Remember back in the good old days when you cl...  2018-07-24T04:49:21.000Z\n",
       "9  canât keep a snapchat streak because im not ...  2018-07-24T04:50:12.000Z"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "df = pd.read_csv(\"csvNewResults.csv\", encoding = 'latin-1')\n",
    "# above line will be different depending on where you saved your data, and your file name\n",
    "df.drop(['id','keyword','handle','replies','retweets','likes'],axis=1,inplace=True)\n",
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['snapchat so worthless now',\n",
       " 'snapchat s lame just text me',\n",
       " 'if your bff doesn t share her his location with you on snapchat is she he really your bff haha',\n",
       " 'doing shit for twitter instagram snapchat or facebook doesn t get you nowhere in real life',\n",
       " 'your mcm typed out violence isn t the answer on a black screen for his snapchat story and thought he did something',\n",
       " 'women please treat your man better i m tired of getting deleted then re added on snapchat',\n",
       " 'dear snapchat please apply a all streaks button on the next update',\n",
       " 'luis is big mad i lost our snapchat streak lmaoohmuforstreaksooo pic twitter com didrohxzwo',\n",
       " 'remember back in the good old days when you clicked through snapchat stories for entertainment instead of just clearing them out of annoyance ahhhh',\n",
       " 'can t keep a snapchat streak because im not committed to anything',\n",
       " 'if you don t like what i post on snapchat please remove me you won t be missed',\n",
       " 'the flashback memories on snapchat give me bad vibes bc mine are full of people i don t associate w anymore like no thank you',\n",
       " 'snapchat stays reminding me daily how completely different my life was a year ago',\n",
       " 'snapchat s year ago today is hands down their best new feature',\n",
       " 'andd if he only gives you his snapchat and not his number well good luck charlie',\n",
       " 'snapchat flashbacks rlly showing me how much my life has changed',\n",
       " 'snapchat is dead',\n",
       " 'if i snapchat you throughout the day then you must be something special because i hate replying to people',\n",
       " 'twitter facebook insta snapchat too humourpic twitter com snirnfdkgz',\n",
       " 'brand new f ck show right now on my private snapchat watch for free pic twitter com mfxcwhcwmr',\n",
       " 'shot on snap spectacles aruba pic twitter com hehyhsdv p',\n",
       " 'please stop sharing the video snapchat of nia s body in the bart station the man has been caught and that does nothing but spread even more trauma',\n",
       " 'girls be like buy my premium snapchat pic twitter com beg hvr ty',\n",
       " 'spencer and taylor just narrated snapchat filters and i ve never seen anything funnier twitter com j ecfroqpc',\n",
       " 'ima need snapchat to quit showing me memories from last year making me all sad n shit',\n",
       " 'here s a quick step by step guide on how to use victor magtanggol stickers on your instagram and snapchat magtanggol must see victor magtanggol stickers now available on instagram story utm source gmaentertainment utm medium twitter utm campaign tv',\n",
       " 'lollll follow me on snapchat it s fucking free sinslifedotcom pic twitter com lhrecobqi',\n",
       " 'i know you re not a snapchat filter but i really wanna see how you d look on my face',\n",
       " 'honestly snapchat memories flashbacks were made to put you in your feels',\n",
       " 'so q has a statement out in arabic english published on snapchat insta because her filipino maid comments were misrepresented pic twitter com b xkcwrbwa',\n",
       " 'kuwaiti beauty blogger q has her twitter acct locked but has been active on snapchat instagram m followers defends her filipino maid comments and yep she uses those lines we re muslims we re arabs people of manners we re not racists etc',\n",
       " 'but snapchat out here letting a sister prosper pic twitter com h wywov',\n",
       " 'if ur main form of communication is snapchat i hate you',\n",
       " 'never look back at your snapchat memories omg',\n",
       " 'as part of the escalating wave of knife crime gripping london young people have started awarding themselves points for rival stabbings and social media specifically snapchat only catalyzes the violence those on the frontlines told us via pic twitter com o h nc wqa',\n",
       " 'can we take a moment not to talk about ix ine past yeah maybe he pled guilty to three felony counts of use of a child in a sexual performance and once joked on a snapchat video saying he s a happy free rapist and i forgot the point i was making dashawnj status',\n",
       " 'boys on s snapchat mtvhottest sospic twitter com dezrcrjle',\n",
       " 'thanks to kanter for a great piece on the launch of on as well as funding our upcoming advocacy platform signs pinknews as snapchat discover first lgbt partner r us ir t',\n",
       " 'before uploading your snapchat pic verify it with your bestie some people look like dead rat who got crushed under wheels',\n",
       " 'you are owing you say you don t have money but you re always popping bottles every weekend and posting on snap chat are you mad tellitlikeitistuesdays',\n",
       " 'opens snapchat camera pic twitter com b h t eje',\n",
       " 'really psyched to tell you why i ve been bailing on all social invitations for the last few months tomorrow launches as the first lgbt publisher on discover signs pinknews as snapchat discover first lgbt partner',\n",
       " 'treat your girl better i m tired of getting deleted and added on snapchat',\n",
       " 'it is a well known fact that amongst the samoyed breed of dog the most popular hobby for yodellers aged is applying snapchat filters to themselves pic twitter com r wrkutai',\n",
       " 'today on ig my mate posted her and her mans year aniv and like the funny part was i used to have the baddest crush on her bf he worked at coles and so did my mate every time i would go to coles i would always snapchat him and say shit like bae working hard',\n",
       " 'after losing traffic because of facebook s algorithm change pinknews is launching on snapchat discover snap is a social platform that considers publishers to be business partners rather than a platform you fight with about algorithm changes',\n",
       " 'pretty sure i m the only girl who doesn t care about snapchat streaks',\n",
       " 'we made it onto mtv snapchat discover pic twitter com nnuqph y s',\n",
       " 'on a couple occasions you literally asked to see my titties and i showed you lol i don t give a fuck again you replied to me a lot on here and snap chat pic twitter com rlghzynul',\n",
       " 'graduating this week check out our facebook instagram and snapchat stories and igtv videos every day to see what s going on captured by our students and digital media gurus pic twitter com ir cpnvoj',\n",
       " 'gotta love snapchat filters pic twitter com hyzzj zkqc',\n",
       " 'when you re talking to a lad on snapchat late at night n they decide it s not conversation they want anymore pic twitter com zz wes gmz',\n",
       " 'people who still don t have a bitmoji on snapchat irritate me and i don t know why',\n",
       " 'my social life right now is snapchatting someone once and them achieving status of best friend in snapchat',\n",
       " 'don t trust anyone on snapchat who doesn t have a bitmoji',\n",
       " 'trying to prove a point retweet for favs fav for retweets check out my soundcloud follow me on snapchat and insta just please for the love of god give me attention',\n",
       " 'relationship goals she s as excited to see me as a basic white girl gets when her fav snapchat filter comes back',\n",
       " 'psa if this person ever adds u on snapchat block them immediately he sent obvs dick pics but when i was like wtf he sent back edited versions of my own selfies and it s just very creepy pic twitter com pphu a e o',\n",
       " 'snapchat should notify you if you re about to lose a streak',\n",
       " 'i wish people put more effort into their snapchat streaks like come on is it really worth snapchatting if you can t even show your face or something interesting i don t want to hear my phone buzz open it click on snapchat open your snap for it just to be your floor',\n",
       " 'snapchat please give us an update with story notifications it s a necessity',\n",
       " 'im so happy ariana is using moonlightbae again her snapchat stories always make me the happiest',\n",
       " 'observation readiness test athlete enters weight room wearing headphones and looking at snapchat athlete enters weight room yawning and grabs a foam roll athlete enters weight room with a smile on their face and claims the speaker rights circle which applies',\n",
       " 'ariana is actually using snapchat omg my heart is so full i fuckin adore her',\n",
       " 'whenthingsgetawkward during text messages i send funny snapchat pics pic twitter com zjd yc ww',\n",
       " 'we are in detroit to day for football media day keep a look out for am jg and neal taking over our snapchat and instagram accounts twitter com sv pbrdn at hall of legends',\n",
       " 'when you see her snapchat a car dashboard pic twitter com vrt ph t o',\n",
       " 'imagine what arianas working on in la she posted a snapchat story with the caption filming and now she s up pretty early ohhh girlie doing some secretive stuff',\n",
       " 'girls that film themselves posing on snapchat or instagram make me so uncomfortable',\n",
       " 'ariana grande via snapchat story pic twitter com uvwgrtumco',\n",
       " 'i hate when people with androids try to argue that their phones are better than iphones literally take a video on snapchat and try to tell me that again',\n",
       " 'im happy that ariana is posting on snapchat but a tiny bit on instagram also i love knowing she s okay and happy and off most of the negativity im soft it s what she deserves',\n",
       " 'snapchat opened up all its public snaps to journalists opened all its public snaps journalists',\n",
       " 'snapchat queen fatima khan guilty of boyfriend death',\n",
       " 'snapchat addict who had her boyfriend killed and filmed him bleeding to death is facing years behind bars pic twitter com ebfq sptl',\n",
       " 'ariana s snapchat story july pic twitter com luii sfoaw',\n",
       " 'i really love her on snapchat so much idk why but it feels so much more intimate n personal to us pic twitter com mw mcd dw',\n",
       " 'first message i got this morning on snapchat lmfao stilltitty tittytuesday pic twitter com lzilcen z',\n",
       " 'there was a day span in where said all of these things mlk would be a republican today jesus christ hung out with muslims we don t need the epa environmental regulations because if there were pollution problems people would post them on snapchat',\n",
       " 'snapchat queen who posted video of dying boyfriend found guilty over death news fatima khan snapchat queen guilty manslaughter boyfriend dying video khalid safi a html utm campaign echobox utm medium social utm source twitter echobox',\n",
       " 'ladies if you haven t seen my snapchat story recently well good luck charlie pic twitter com zahl bnd',\n",
       " 'some of my favorite snapchat filters su pic twitter com blmibrdnkk',\n",
       " 'things i don t understand families who go out to eat together and then spend the entire time on their respective smartphones parents who let their young children stay up past pm snapchat common core math why my kids call each other the goat',\n",
       " 'when on snapchat ft the chinese collar snapchat pic twitter com thil bhuaa',\n",
       " 'snapchat memories reminding you how far you ve come in a year',\n",
       " 'the snapchat queen who filmed her boyfriend s death',\n",
       " 'wow im on buzzfeed ladbibles snapchat story',\n",
       " 'these snapchat memories they keep warming my heart up but it also hurts because my dear friend has died and he has not gotten justice and i really miss him all of the stories have him in it i miss him so much it hurts if heaven is real that is where he is rip trapper',\n",
       " 't minus days until gator growl visit our table in turlington to buy your gator growl tickets today from am pm and check out our snapchat filter not in gainesville just visit growl tickets artist bvrrwidgetid to purchase tickets online letthegatorgrowl floridabluekeypic twitter com qptcydubkc',\n",
       " 'y all ugly caring how much someone posts on their snapchat let ppl record concerts and shows as much as they want they get to look back at those moments and find happiness in them',\n",
       " 'the future is so fun here is proving a search result that he is no longer alive wrong via a video of a dancing bitmoji of himself next to his actual self signing bills',\n",
       " 'what is the achievement of having streaks on snapchat like if we don t talk what s the point sending me streaks everyday',\n",
       " 'tip of the day stop posting lyrics and dashboard videos on snapchat',\n",
       " 'lmao snapchat is wild pic twitter com ewdypenbyj',\n",
       " 'since ariana is back on snapchat here s a thread of her best moments there pic twitter com hxmdmc',\n",
       " 'middle part sew in with closure dayarnalvsha follow me on ig slayedbydayarnalvsha snapchat unvshayy location hyattsville md book with me by texting the number in my bio pic twitter com cizwc k dv',\n",
       " 'nigga treat your girl better i m tired of getting deleted and added back again on snapchat',\n",
       " 'being the taylor swift girl means i get daily snapchat videos from people when they re listening to taylor my enemies have to think about me every time they hear her name and i just get to be associated with an amazing geniune talented queen i love it',\n",
       " 'my sister has streaks on snapchat i can hardly keep what the hell',\n",
       " 'literally my social media instagram doesn t try to fangirl much bc too many locals follow snapchat fangirls sometimes twitter where i switch to my hannah montana self and fangirl and use twitter stan like i m illiterate']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "df['pre_clean_len'] = [len(t) for t in df.body]\n",
    "\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "tok = WordPunctTokenizer()\n",
    "pat1 = r'@[A-Za-z0-9]+'\n",
    "pat2 = r'https?://[A-Za-z0-9./]+'\n",
    "combined_pat = r'|'.join((pat1, pat2))\n",
    "def tweet_cleaner(body):\n",
    "    soup = BeautifulSoup(body, 'lxml')\n",
    "    souped = soup.get_text()\n",
    "    stripped = re.sub(combined_pat, '', souped)\n",
    "    try:\n",
    "        clean = stripped.decode(\"utf-8-sig\").replace(u\"\\ufffd\", \"?\")\n",
    "    except:\n",
    "        clean = stripped\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", clean)\n",
    "    lower_case = letters_only.lower()\n",
    "    words = tok.tokenize(lower_case)\n",
    "    return (\" \".join(words)).strip()\n",
    "testing = df.body[:100]\n",
    "test_result = []\n",
    "for t in testing:\n",
    "    test_result.append(tweet_cleaner(t))\n",
    "test_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16894 entries, 0 to 16893\n",
      "Data columns (total 3 columns):\n",
      "body             16894 non-null object\n",
      "date_tweeted     16894 non-null object\n",
      "pre_clean_len    16894 non-null int64\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 396.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning and parsing the tweets...\n",
      "\n",
      "Tweets 10000 of 16894 has been processed\n"
     ]
    }
   ],
   "source": [
    "nums = [0,16894]\n",
    "print (\"Cleaning and parsing the tweets...\\n\")\n",
    "clean_tweet_texts = []\n",
    "for i in range(nums[0],nums[1]):\n",
    "    if( (i+1)%10000 == 0 ):\n",
    "        print(\"Tweets %d of %d has been processed\" % ( i+1, nums[1] ))                                                                    \n",
    "    clean_tweet_texts.append(tweet_cleaner(df['body'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = pd.DataFrame(clean_tweet_texts,columns=['body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>snapchat so worthless now</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>snapchat s lame just text me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>if your bff doesn t share her his location wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>doing shit for twitter instagram snapchat or f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>your mcm typed out violence isn t the answer o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body\n",
       "0                          snapchat so worthless now\n",
       "1                       snapchat s lame just text me\n",
       "2  if your bff doesn t share her his location wit...\n",
       "3  doing shit for twitter instagram snapchat or f...\n",
       "4  your mcm typed out violence isn t the answer o..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "tok = WordPunctTokenizer()\n",
    "\n",
    "pat1 = r'@[A-Za-z0-9_]+'\n",
    "pat2 = r'https?://[^ ]+'\n",
    "combined_pat = r'|'.join((pat1, pat2))\n",
    "www_pat = r'www.[^ ]+'\n",
    "negations_dic = {\"isn't\":\"is not\", \"aren't\":\"are not\", \"wasn't\":\"was not\", \"weren't\":\"were not\",\n",
    "                \"haven't\":\"have not\",\"hasn't\":\"has not\",\"hadn't\":\"had not\",\"won't\":\"will not\",\n",
    "                \"wouldn't\":\"would not\", \"don't\":\"do not\", \"doesn't\":\"does not\",\"didn't\":\"did not\",\n",
    "                \"can't\":\"can not\",\"couldn't\":\"could not\",\"shouldn't\":\"should not\",\"mightn't\":\"might not\",\n",
    "                \"mustn't\":\"must not\"}\n",
    "neg_pattern = re.compile(r'\\b(' + '|'.join(negations_dic.keys()) + r')\\b')\n",
    "\n",
    "def tweet_cleaner_updated(text):\n",
    "    soup = BeautifulSoup(text, 'lxml')\n",
    "    souped = soup.get_text()\n",
    "    try:\n",
    "        bom_removed = souped.decode(\"utf-8-sig\").replace(u\"\\ufffd\", \"?\")\n",
    "    except:\n",
    "        bom_removed = souped\n",
    "    stripped = re.sub(combined_pat, '', bom_removed)\n",
    "    stripped = re.sub(www_pat, '', stripped)\n",
    "    lower_case = stripped.lower()\n",
    "    neg_handled = neg_pattern.sub(lambda x: negations_dic[x.group()], lower_case)\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", neg_handled)\n",
    "    words = [x for x  in tok.tokenize(letters_only) if len(x) > 1]\n",
    "    return (\" \".join(words)).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>snapchat so worthless now</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>snapchat s lame just text me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>if your bff doesn t share her his location wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>doing shit for twitter instagram snapchat or f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>your mcm typed out violence isn t the answer o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body\n",
       "0                          snapchat so worthless now\n",
       "1                       snapchat s lame just text me\n",
       "2  if your bff doesn t share her his location wit...\n",
       "3  doing shit for twitter instagram snapchat or f...\n",
       "4  your mcm typed out violence isn t the answer o..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cvec = CountVectorizer(min_df = 1)\n",
    "cvec.fit(clean_df.body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cvec.get_feature_names())\n",
    "clean_df.to_csv('clean_data.csv',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_matrix = cvec.transform(clean_df.body)\n",
    "\n",
    "clean_df_new = cvec.transform(clean_df.body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 28192 features per sample; expecting 10572579",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-33db1adde0f1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msentimentAnal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclean_df_new\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    322\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m         \"\"\"\n\u001b[1;32m--> 324\u001b[1;33m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    303\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m             raise ValueError(\"X has %d features per sample; expecting %d\"\n\u001b[1;32m--> 305\u001b[1;33m                              % (X.shape[1], n_features))\n\u001b[0m\u001b[0;32m    306\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    307\u001b[0m         scores = safe_sparse_dot(X, self.coef_.T,\n",
      "\u001b[1;31mValueError\u001b[0m: X has 28192 features per sample; expecting 10572579"
     ]
    }
   ],
   "source": [
    "sentimentAnal.predict(clean_df_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vect = TfidfVectorizer(min_df= 1, analyzer = \"word\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect.fit(clean_df)\n",
    "clean_df_dtm = vect.transform(clean_df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 1 features per sample; expecting 10572579",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-15e49e85d657>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msentimentAnal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclean_df_dtm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    322\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m         \"\"\"\n\u001b[1;32m--> 324\u001b[1;33m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    303\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m             raise ValueError(\"X has %d features per sample; expecting %d\"\n\u001b[1;32m--> 305\u001b[1;33m                              % (X.shape[1], n_features))\n\u001b[0m\u001b[0;32m    306\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    307\u001b[0m         scores = safe_sparse_dot(X, self.coef_.T,\n",
      "\u001b[1;31mValueError\u001b[0m: X has 1 features per sample; expecting 10572579"
     ]
    }
   ],
   "source": [
    "sentimentAnal.predict(clean_df_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = sentimentAnal.predict(clean_df.body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sen = ['girl is so ugly', 'im hungry']\n",
    "\n",
    "sentimentAnal.predict(sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=['hello this sucks'].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-7cf2b804b7e9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msentimentAnal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"hello this sucks\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    322\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m         \"\"\"\n\u001b[1;32m--> 324\u001b[1;33m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    298\u001b[0m                                  \"yet\" % {'name': type(self).__name__})\n\u001b[0;32m    299\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 300\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    301\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m         \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    439\u001b[0m                     \u001b[1;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m                     \u001b[1;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 441\u001b[1;33m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[0;32m    442\u001b[0m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m             \u001b[1;31m# To ensure that array flags are maintained\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=['hello this sucks'].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "sentimentAnal.predict([\"hello this sucks\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
